{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YeNh8DIBkgj4"
   },
   "source": [
    "# LSTM on Kaggle's Quora Question Pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 904
    },
    "colab_type": "code",
    "id": "XY_R3I_vgPEW",
    "outputId": "59fe3169-dc73-470e-e24f-e2db215784dd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (1.18.5)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (1.0.4)\n",
      "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas) (2018.9)\n",
      "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from pandas) (1.18.5)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas) (2.8.1)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.6.1->pandas) (1.12.0)\n",
      "Requirement already satisfied: spacy in /usr/local/lib/python3.6/dist-packages (2.2.4)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy) (2.0.3)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.18.5)\n",
      "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.0.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (2.23.0)\n",
      "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (0.4.1)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (4.41.1)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (0.6.0)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.0.2)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy) (47.1.1)\n",
      "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.1.3)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy) (3.0.2)\n",
      "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.0.2)\n",
      "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (7.4.0)\n",
      "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy) (1.6.0)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.9)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2020.4.5.1)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (1.24.3)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy) (3.1.0)\n",
      "Requirement already satisfied: nltk in /usr/local/lib/python3.6/dist-packages (3.2.5)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from nltk) (1.12.0)\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (1.5.0+cu101)\n",
      "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch) (0.16.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch) (1.18.5)\n",
      "Requirement already satisfied: spacy in /usr/local/lib/python3.6/dist-packages (2.2.4)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy) (3.0.2)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.18.5)\n",
      "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (0.4.1)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy) (47.1.1)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy) (2.0.3)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (0.6.0)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.0.2)\n",
      "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.1.3)\n",
      "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.0.2)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (4.41.1)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (2.23.0)\n",
      "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (7.4.0)\n",
      "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.0.0)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.9)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (1.24.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2020.4.5.1)\n",
      "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy) (1.6.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy) (3.1.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install numpy\n",
    "!pip install pandas\n",
    "!pip install spacy\n",
    "!pip install nltk\n",
    "!pip install torch\n",
    "!pip install spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "T0MUk5gOkgj7"
   },
   "source": [
    "First, lets import all the necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "08Hqa6W5mlPd"
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import os\n",
    "import spacy\n",
    "import string\n",
    "import re\n",
    "import numpy as np\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "import spacy\n",
    "from spacy.symbols import ORTH\n",
    "from collections import Counter\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "import torch.cuda\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "colab_type": "code",
    "id": "-bDpf1c9gjP1",
    "outputId": "170a779a-4c30-4c42-8f86-97fb561136a5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JANlxNsQkgkD"
   },
   "source": [
    "### Global variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nqdbDZZHgVnZ"
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "PATH = Path(\"/content/drive/My Drive/Colab Notebooks/DL/deep-learning-with-pytorch/data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bQwu13zukgkE"
   },
   "outputs": [],
   "source": [
    "# File paths\n",
    "TRAIN_CSV = PATH/'train.csv'\n",
    "TEST_CSV = PATH/'test.csv'\n",
    "EMBEDDING_FILE = PATH/'GoogleNews-vectors-negative300.bin.gz'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "u-d8rfdPkgkJ"
   },
   "source": [
    "## Create embedding matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7d9HZUcWkgkK"
   },
   "outputs": [],
   "source": [
    "# Load training and test set\n",
    "train_df = pd.read_csv(TRAIN_CSV)\n",
    "test_df = pd.read_csv(TEST_CSV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "3rdZNG4fhErI",
    "outputId": "93d16b17-ff60-4512-ca7a-7ffe950443f7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "stops = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GEAmaynuhG9k"
   },
   "outputs": [],
   "source": [
    "def text_to_word_list(text):\n",
    "    ''' Pre process and convert texts to a list of words '''\n",
    "    text = str(text)\n",
    "    text = text.lower()\n",
    "\n",
    "    # Clean the text\n",
    "    text = re.sub(r\"[^A-Za-z0-9^,!.\\/'+-=]\", \" \", text)\n",
    "    text = re.sub(r\"what's\", \"what is \", text)\n",
    "    text = re.sub(r\"\\'s\", \" \", text)\n",
    "    text = re.sub(r\"\\'ve\", \" have \", text)\n",
    "    text = re.sub(r\"can't\", \"cannot \", text)\n",
    "    text = re.sub(r\"n't\", \" not \", text)\n",
    "    text = re.sub(r\"i'm\", \"i am \", text)\n",
    "    text = re.sub(r\"\\'re\", \" are \", text)\n",
    "    text = re.sub(r\"\\'d\", \" would \", text)\n",
    "    text = re.sub(r\"\\'ll\", \" will \", text)\n",
    "    text = re.sub(r\",\", \" \", text)\n",
    "    text = re.sub(r\"\\.\", \" \", text)\n",
    "    text = re.sub(r\"!\", \" ! \", text)\n",
    "    text = re.sub(r\"\\/\", \" \", text)\n",
    "    text = re.sub(r\"\\^\", \" ^ \", text)\n",
    "    text = re.sub(r\"\\+\", \" + \", text)\n",
    "    text = re.sub(r\"\\-\", \" - \", text)\n",
    "    text = re.sub(r\"\\=\", \" = \", text)\n",
    "    text = re.sub(r\"'\", \" \", text)\n",
    "    text = re.sub(r\"(\\d+)(k)\", r\"\\g<1>000\", text)\n",
    "    text = re.sub(r\":\", \" : \", text)\n",
    "    text = re.sub(r\" e g \", \" eg \", text)\n",
    "    text = re.sub(r\" b g \", \" bg \", text)\n",
    "    text = re.sub(r\" u s \", \" american \", text)\n",
    "    text = re.sub(r\"\\0s\", \"0\", text)\n",
    "    text = re.sub(r\" 9 11 \", \"911\", text)\n",
    "    text = re.sub(r\"e - mail\", \"email\", text)\n",
    "    text = re.sub(r\"j k\", \"jk\", text)\n",
    "    text = re.sub(r\"\\s{2,}\", \" \", text)\n",
    "\n",
    "    text = text.split()\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "f8ClzCCcg3vE"
   },
   "outputs": [],
   "source": [
    "# Prepare embedding\n",
    "vocabulary = dict()\n",
    "inverse_vocabulary = ['<unk>']  # '<unk>' will never be used, it is only a placeholder for the [0, 0, ....0] embedding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "id": "Bve_9hGtn21F",
    "outputId": "a0f3754f-b20d-4819-cb00-80b9c4d78b4c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:253: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
      "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
     ]
    }
   ],
   "source": [
    "word2vec = KeyedVectors.load_word2vec_format(EMBEDDING_FILE, binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gXiDBfPOhW4s"
   },
   "outputs": [],
   "source": [
    "questions_cols = ['question1', 'question2']\n",
    "\n",
    "# Iterate over the questions only of both training and test datasets\n",
    "for dataset in [train_df, test_df]:\n",
    "    for index, row in dataset.iterrows():\n",
    "\n",
    "        # Iterate through the text of both questions of the row\n",
    "        for question in questions_cols:\n",
    "\n",
    "            q2n = []  # q2n -> question numbers representation\n",
    "            for word in text_to_word_list(row[question]):\n",
    "\n",
    "                # Check for unwanted words\n",
    "                if word in stops and word not in word2vec.vocab:\n",
    "                    continue\n",
    "\n",
    "                if word not in vocabulary:\n",
    "                    vocabulary[word] = len(inverse_vocabulary)\n",
    "                    q2n.append(len(inverse_vocabulary))\n",
    "                    inverse_vocabulary.append(word)\n",
    "                else:\n",
    "                    q2n.append(vocabulary[word])\n",
    "\n",
    "            # Replace questions as word to question as number representation\n",
    "            dataset.at[index, question] = q2n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6iQlFsuazNAY"
   },
   "outputs": [],
   "source": [
    "embedding_dim = 300\n",
    "embeddings = 1 * np.random.randn(len(vocabulary) + 1, embedding_dim)  # This will be the embedding matrix\n",
    "embeddings[0] = 0  # So that the padding will be ignored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "WzIxcclqG_zB",
    "outputId": "eb761ac6-f987-4061-9945-abfc0a9cae2a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "121319"
      ]
     },
     "execution_count": 14,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VlDBXASJzJJk"
   },
   "outputs": [],
   "source": [
    "# Build the embedding matrix\n",
    "for word, index in vocabulary.items():\n",
    "    if word in word2vec.vocab:\n",
    "        embeddings[index] = word2vec.word_vec(word)\n",
    "\n",
    "#del word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "COfWRKgmhM6B",
    "outputId": "964e782a-921d-47e5-c091-f8ec283597ae"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(121320, 36396000)"
      ]
     },
     "execution_count": 18,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(embeddings), embeddings.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "9Os5mkXAhg9X",
    "outputId": "d1198618-de0b-4b31-b363-9bc18a208a3b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "300"
      ]
     },
     "execution_count": 24,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings[0].size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nkjxMWvRVCkH"
   },
   "outputs": [],
   "source": [
    "#saving embeddings to drive to save time\n",
    "np.savetxt(PATH/\"embeddings.csv\", embeddings, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sPOvTRXegMIz"
   },
   "outputs": [],
   "source": [
    "#load embeddings from drive\n",
    "from numpy import genfromtxt\n",
    "embeddings = genfromtxt(PATH/'embeddings.csv', delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Jif9md8-KTNs"
   },
   "outputs": [],
   "source": [
    "# Save the embeddings to file\n",
    "train_df.to_pickle(PATH/\"train_df.pkl\")\n",
    "test_df.to_pickle(PATH/\"test_df.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 419
    },
    "colab_type": "code",
    "id": "lqIhKB58MS4u",
    "outputId": "0cae1bed-cd25-401f-ebed-1ff6d8108704"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>qid1</th>\n",
       "      <th>qid2</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>is_duplicate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>[1, 2, 3, 4, 5, 4, 6, 7, 8, 9, 10, 8, 11]</td>\n",
       "      <td>[1, 2, 3, 4, 5, 4, 6, 7, 8, 9, 10]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>[1, 2, 3, 12, 13, 14, 15, 16, 15, 17, 18]</td>\n",
       "      <td>[1, 19, 20, 21, 3, 22, 23, 24, 3, 13, 14, 15, ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>[26, 27, 16, 28, 3, 29, 30, 31, 32, 33, 34, 35]</td>\n",
       "      <td>[26, 27, 31, 29, 36, 37, 5, 38, 39, 40]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>[41, 42, 16, 43, 44, 45, 26, 27, 16, 46, 47]</td>\n",
       "      <td>[48, 3, 49, 50, 51, 52, 53, 54, 51, 2, 55, 5, ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>[56, 57, 58, 8, 59, 60, 61, 62, 63, 64, 65, 66]</td>\n",
       "      <td>[56, 67, 19, 68, 8, 62, 59]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404285</th>\n",
       "      <td>404285</td>\n",
       "      <td>433578</td>\n",
       "      <td>379845</td>\n",
       "      <td>[26, 184, 3632, 115, 307, 8, 3, 24591, 522, 52...</td>\n",
       "      <td>[26, 184, 3632, 115, 307, 8, 12037, 522, 523, ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404286</th>\n",
       "      <td>404286</td>\n",
       "      <td>18840</td>\n",
       "      <td>155606</td>\n",
       "      <td>[97, 99, 2441, 307, 2, 598, 180, 1822]</td>\n",
       "      <td>[2, 47, 467, 77, 307, 2, 598, 180, 1822]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404287</th>\n",
       "      <td>404287</td>\n",
       "      <td>537928</td>\n",
       "      <td>537929</td>\n",
       "      <td>[1, 2, 57, 11017]</td>\n",
       "      <td>[1, 2, 83, 11017]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404288</th>\n",
       "      <td>404288</td>\n",
       "      <td>537930</td>\n",
       "      <td>537931</td>\n",
       "      <td>[1, 2, 3, 21210, 12592, 534, 2769, 33, 3114, 8...</td>\n",
       "      <td>[16, 42, 1086, 2877, 2854, 2622, 1220, 16, 173...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404289</th>\n",
       "      <td>404289</td>\n",
       "      <td>537932</td>\n",
       "      <td>537933</td>\n",
       "      <td>[1, 2, 139, 401, 2543, 175, 7229]</td>\n",
       "      <td>[1, 2, 47, 139, 401, 2543, 175, 135, 7229]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>404290 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            id  ...  is_duplicate\n",
       "0            0  ...             0\n",
       "1            1  ...             0\n",
       "2            2  ...             0\n",
       "3            3  ...             0\n",
       "4            4  ...             0\n",
       "...        ...  ...           ...\n",
       "404285  404285  ...             0\n",
       "404286  404286  ...             1\n",
       "404287  404287  ...             0\n",
       "404288  404288  ...             0\n",
       "404289  404289  ...             0\n",
       "\n",
       "[404290 rows x 6 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "m1uN-1eAK_Oy"
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_pickle(PATH/\"train_df.pkl\")\n",
    "test_df = pd.read_pickle(PATH/\"test_df.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "5geOONvL4XfW",
    "outputId": "7d152503-f1f0-49d7-93eb-fbf2a9451b34"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3563475, 3)"
      ]
     },
     "execution_count": 111,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xsqGDdkd4c4Z"
   },
   "outputs": [],
   "source": [
    "# Split test data to smaller chunks to run the model to predict output\n",
    "def splitDataFrameIntoSmaller(df, chunkSize = 10000): \n",
    "    listOfDf = list()\n",
    "    numberChunks = len(df) // chunkSize + 1\n",
    "    for i in range(numberChunks):\n",
    "        listOfDf.append(df[i*chunkSize:(i+1)*chunkSize])\n",
    "    return listOfDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "heCWfmDW4x6g"
   },
   "outputs": [],
   "source": [
    "chunks = splitDataFrameIntoSmaller(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "y_6F4TiK5CIY",
    "outputId": "4765b477-bac0-4bbb-e1d3-739903032af1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "357"
      ]
     },
     "execution_count": 18,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C = len(chunks)\n",
    "C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "mzrwkTNI5H7D",
    "outputId": "12c0ae62-81bf-48eb-93d8-e70130e95ea1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10000, 3), (10000, 3))"
      ]
     },
     "execution_count": 19,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks[0].shape, chunks[7].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yJoZwXrn5aVD"
   },
   "outputs": [],
   "source": [
    "# Save test data chunks to file\n",
    "def saveChunks2file(chunks):\n",
    "  for i,chunk in enumerate(chunks):\n",
    "    filename = \"output\"+str(i)+\".pkl\"\n",
    "    chunk.to_pickle(PATH/filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Bc4DquN16yJe"
   },
   "outputs": [],
   "source": [
    "saveChunks2file(chunks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "X_N7QXN_kgkO"
   },
   "source": [
    "## Prepare training and validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2NbUV1f4lHqv"
   },
   "outputs": [],
   "source": [
    "# spacy_tok takes a while. Run it just once\n",
    "def encode_sentence(q1, q2 , N=50, padding_start=False):\n",
    "    #x = spacy_tok(path.read_text())\n",
    "    x1 = np.zeros(N, dtype=np.int32)\n",
    "    x2 = np.zeros(N, dtype=np.int32)\n",
    "    #enc1 = np.array([vocab2index.get(w, vocab2index[\"UNK\"]) for w in x])\n",
    "    l1 = min(N, len(q1))\n",
    "    l2 = min(N, len(q2))\n",
    "    if padding_start:\n",
    "        x1[:l1] = q1[:l1]\n",
    "        x2[:l2] = q2[:l2]\n",
    "    else:\n",
    "        x1[N-l1:] = q1[:l1]\n",
    "        x2[N-l2:] = q2[:l2]\n",
    "    return x1, x2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cy9f2KMvmMWI"
   },
   "outputs": [],
   "source": [
    "X = np.array(train_df[['question1', 'question2']])\n",
    "y = np.array(train_df['is_duplicate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 170
    },
    "colab_type": "code",
    "id": "cYMQgs_smSsk",
    "outputId": "a487c8cf-16a7-47cc-9455-2e935e534a0c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[list([26, 76, 3, 1663, 1237, 5472, 745, 149, 175, 4949, 1237]),\n",
       "        list([41, 330, 3863, 331, 1580, 12991, 212, 1580, 6271, 1393, 1663, 1237, 745])],\n",
       "       [list([84, 16, 401, 942, 11093, 225, 833, 54, 26, 214, 19, 47, 534]),\n",
       "        list([26, 214, 534, 76, 942, 11093, 1864])],\n",
       "       [list([1, 1220, 2, 3, 195, 250, 1096, 251, 91, 817, 3, 147]),\n",
       "        list([1, 99, 1096, 251, 817])],\n",
       "       [list([56, 818, 212, 31956]), list([1, 388, 11099])],\n",
       "       [list([26, 86002, 1221, 1204]),\n",
       "        list([26, 290, 27, 16, 1221, 1204])]], dtype=object)"
      ]
     },
     "execution_count": 17,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test = np.array(test_df[['question1', 'question2']])\n",
    "X_test[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "seW-owCsmGGn",
    "outputId": "1080d2d2-0cec-45ee-97d1-9d9cc15b781d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[list([1, 115, 116, 3, 777, 2800]),\n",
       "         list([1, 115, 116, 98, 777, 2800, 175, 3295, 834])],\n",
       "        [list([2, 83, 1848, 1849, 1018]),\n",
       "         list([115, 1848, 1849, 1824, 3984])],\n",
       "        [list([1, 2, 3, 278, 525, 2670, 446, 2315, 8, 135, 598]),\n",
       "         list([1, 115, 3, 278, 525, 697, 99, 401, 2315, 8, 135, 598, 50, 330, 99, 133, 606])],\n",
       "        [list([56, 1507, 3329, 108, 1188, 4285, 1734, 401, 95, 1755, 3296, 31732, 7046, 8, 2949]),\n",
       "         list([56, 1507, 3329, 108, 2599, 4285, 1734, 401, 95, 1755, 3296, 31732, 7046, 8, 2949])],\n",
       "        [list([1, 84, 16, 97, 36, 162, 7478, 8, 372]),\n",
       "         list([1, 2, 4528, 4017, 8675])]], dtype=object),\n",
       " array([0, 0, 1, 1, 0]))"
      ]
     },
     "execution_count": 16,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "X_train[:5], y_train[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9tm8jIk1mB6b"
   },
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "x1g6weW6l4cN"
   },
   "outputs": [],
   "source": [
    "class QuoraDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.x = [encode_sentence(q1, q2) for q1, q2 in X]\n",
    "        self.y = y\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        x1 = self.x[idx][0]\n",
    "        x2 = self.x[idx][1]\n",
    "        return x1, x2, self.y[idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jqjCsYC7muUL"
   },
   "outputs": [],
   "source": [
    "train_ds = QuoraDataset(X_train, y_train)\n",
    "valid_ds = QuoraDataset(X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "h8ry32TMHu_s",
    "outputId": "fa4aedf6-8e81-4409-ac8c-7a07027c6c55"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3563475"
      ]
     },
     "execution_count": 19,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "_WN6eCpSRBLx",
    "outputId": "933a9746-03e5-4705-c009-e2123b6e1c29"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3563474, 3)"
      ]
     },
     "execution_count": 43,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "PSPNpU9_IDtU",
    "outputId": "aee17d45-4fc0-432f-9839-a0a18fffb462"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, ..., 1, 0, 1])"
      ]
     },
     "execution_count": 248,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "GNoEUrLWnnPH",
    "outputId": "402e32d7-e036-428a-db77-04bd259de103"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           1,  115,  116,    3,  777, 2800], dtype=int32),\n",
       " array([   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    1,  115,  116,\n",
       "          98,  777, 2800,  175, 3295,  834], dtype=int32),\n",
       " 0)"
      ]
     },
     "execution_count": 20,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 238
    },
    "colab_type": "code",
    "id": "6Y3w0TJboKGk",
    "outputId": "41c90dff-d2e3-4d95-b2ff-84b142758791"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[    0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     1,     2,\n",
       "             47,   139,   715,     8, 13373,    11,  7580,   536,   731,  8894]],\n",
       "        dtype=torch.int32),\n",
       " tensor([[    0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     1,     2,    47,   139,\n",
       "           1026,     8, 13373,    11,  7580,   536,   731,  8894,   638,   197]],\n",
       "        dtype=torch.int32),\n",
       " tensor([1]))"
      ]
     },
     "execution_count": 21,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trn_dl = DataLoader(train_ds, batch_size=1, shuffle=True)\n",
    "x1,x2, y= next(iter(trn_dl))\n",
    "\n",
    "x1,x2, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "hKPPO1FuoOSB",
    "outputId": "35fb6d68-72a6-4bd4-ec55-64ad5debc65a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 50]), torch.Size([1, 50]), torch.Size([1]))"
      ]
     },
     "execution_count": 22,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1.shape,x2.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gjPP1ZtgmI_C"
   },
   "source": [
    "## LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tXwuE2caJZjL"
   },
   "outputs": [],
   "source": [
    "def save_model(m, p): torch.save(m.state_dict(), p)\n",
    "    \n",
    "def load_model(m, p): m.load_state_dict(torch.load(p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hck8QEMsi-l6"
   },
   "outputs": [],
   "source": [
    "class LSTMV0Model(torch.nn.Module) :\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, pretrained_weights=None) :\n",
    "        super(LSTMV0Model,self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.embeddings = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)\n",
    "        if pretrained_weights is not None:\n",
    "            self.embeddings.weight.data.copy_(torch.from_numpy(pretrained_weights))\n",
    "            self.embeddings.weight.requires_grad = False ## freeze embeddings\n",
    "\n",
    "        self.q1_lstm = nn.LSTM(embedding_dim, hidden_dim, batch_first=True)\n",
    "        self.q2_lstm = nn.LSTM(embedding_dim, hidden_dim, batch_first=True)\n",
    "        \n",
    "    def forward(self, x1, x2):\n",
    "        x1 = self.embeddings(x1)\n",
    "        x2 = self.embeddings(x2)\n",
    "        out_pack, (ht1, ct) = self.q1_lstm(x1)\n",
    "        out_pack, (ht2, ct) = self.q1_lstm(x2)\n",
    "        \n",
    "        q1 = ht1[-1]\n",
    "        q2 = ht2[-1]\n",
    "        \n",
    "        dist = torch.norm(q1-q2, dim=1)\n",
    "        dist = torch.exp(-dist)\n",
    "        return dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "OiehQF9-ZzxW",
    "outputId": "8890d5e8-728b-4f15-968a-44dc20d93679"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.5726], grad_fn=<ExpBackward>) tensor([1]) 1\n",
      "tensor(0.5576, grad_fn=<BinaryCrossEntropyBackward>) 0.5576372146606445\n"
     ]
    }
   ],
   "source": [
    "model_test = LSTMV0Model(len(embeddings), 300, 100, pretrained_weights=embeddings)\n",
    "y_pred = model_test(x1.long(), x2.long())\n",
    "print(y_pred, y, y.unsqueeze(1).shape[0])\n",
    "loss = F.binary_cross_entropy(y_pred.unsqueeze(1), y.float().unsqueeze(1))\n",
    "print(loss, loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6DcgGDCzpcf_"
   },
   "outputs": [],
   "source": [
    "def update_optimizer(optimizer, lr):\n",
    "    for i, param_group in enumerate(optimizer.param_groups):\n",
    "        param_group[\"lr\"] = lr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "U4zdbc4ppDWN"
   },
   "outputs": [],
   "source": [
    "def train_epocs(model, optimizer, train_dl, valid_dl, model_name, epochs=10):\n",
    "    for i in range(epochs):\n",
    "        model.train()\n",
    "        sum_loss = 0.0\n",
    "        total = 0\n",
    "        best_val_acc = 0.0\n",
    "        for x1, x2, y in train_dl:\n",
    "            x1 = x1.long().cuda()\n",
    "            x2 = x2.long().cuda()\n",
    "            y = y.float().cuda()\n",
    "            y_pred = model(x1, x2)\n",
    "            optimizer.zero_grad()\n",
    "            loss = F.binary_cross_entropy(y_pred.unsqueeze(1), y.unsqueeze(1))\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            sum_loss += loss.item()*y.shape[0]\n",
    "            total += y.shape[0]\n",
    "        val_loss, val_acc = val_metrics(model, valid_dl)\n",
    "        print(\"train loss %.3f val loss %.3f and val accuracy %.3f\" % (sum_loss/total, val_loss, val_acc))\n",
    "        if best_val_acc < val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            path = \"{0}/quora_models/model_{2}_acc_{1:.0f}.pth\".format(PATH, 100*val_acc, model_name) \n",
    "            save_model(model, path)\n",
    "            print(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2GSerN3opGiD"
   },
   "outputs": [],
   "source": [
    "def val_metrics(model, valid_dl):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    sum_loss = 0.0\n",
    "    for x1, x2, y in valid_dl:\n",
    "        x1 = x1.long().cuda()\n",
    "        x2 = x2.long().cuda()\n",
    "        y = y.float().cuda()\n",
    "        y_hat = model(x1, x2)\n",
    "        loss = F.binary_cross_entropy(y_hat.unsqueeze(1), y.unsqueeze(1))\n",
    "        y_pred = y_hat > 0.5\n",
    "        correct += (y_pred.unsqueeze(1).float() == y.unsqueeze(1)).float().sum()\n",
    "        total += y.shape[0]\n",
    "        sum_loss += loss.item()*y.shape[0]\n",
    "    return sum_loss/total, correct/total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "t8qG73cymxvj"
   },
   "source": [
    "## Training model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qwjf_P_pjHOS"
   },
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "train_dl = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
    "valid_dl = DataLoader(valid_ds, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eHZI5jp_o3Dd"
   },
   "outputs": [],
   "source": [
    "model = LSTMV0Model(len(embeddings), 300, 100, pretrained_weights=embeddings).cuda()\n",
    "\n",
    "parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
    "optimizer = torch.optim.Adam(parameters, lr=0.001)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 527
    },
    "colab_type": "code",
    "id": "gHHVJfiNs5_U",
    "outputId": "f7fc7efe-6dc8-4331-9e0b-1c83f578100c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss 0.536 val loss 0.514 and val accuracy 0.776\n",
      "/content/drive/My Drive/Colab Notebooks/DL/deep-learning-with-pytorch/data/quora_models/model_LSTM_acc_78.pth\n",
      "train loss 0.483 val loss 0.488 and val accuracy 0.801\n",
      "/content/drive/My Drive/Colab Notebooks/DL/deep-learning-with-pytorch/data/quora_models/model_LSTM_acc_80.pth\n",
      "train loss 0.461 val loss 0.474 and val accuracy 0.809\n",
      "/content/drive/My Drive/Colab Notebooks/DL/deep-learning-with-pytorch/data/quora_models/model_LSTM_acc_81.pth\n",
      "train loss 0.445 val loss 0.465 and val accuracy 0.811\n",
      "/content/drive/My Drive/Colab Notebooks/DL/deep-learning-with-pytorch/data/quora_models/model_LSTM_acc_81.pth\n",
      "train loss 0.433 val loss 0.459 and val accuracy 0.817\n",
      "/content/drive/My Drive/Colab Notebooks/DL/deep-learning-with-pytorch/data/quora_models/model_LSTM_acc_82.pth\n",
      "train loss 0.423 val loss 0.455 and val accuracy 0.819\n",
      "/content/drive/My Drive/Colab Notebooks/DL/deep-learning-with-pytorch/data/quora_models/model_LSTM_acc_82.pth\n",
      "train loss 0.414 val loss 0.451 and val accuracy 0.819\n",
      "/content/drive/My Drive/Colab Notebooks/DL/deep-learning-with-pytorch/data/quora_models/model_LSTM_acc_82.pth\n",
      "train loss 0.407 val loss 0.453 and val accuracy 0.823\n",
      "/content/drive/My Drive/Colab Notebooks/DL/deep-learning-with-pytorch/data/quora_models/model_LSTM_acc_82.pth\n",
      "train loss 0.400 val loss 0.447 and val accuracy 0.822\n",
      "/content/drive/My Drive/Colab Notebooks/DL/deep-learning-with-pytorch/data/quora_models/model_LSTM_acc_82.pth\n",
      "train loss 0.394 val loss 0.448 and val accuracy 0.822\n",
      "/content/drive/My Drive/Colab Notebooks/DL/deep-learning-with-pytorch/data/quora_models/model_LSTM_acc_82.pth\n",
      "train loss 0.388 val loss 0.446 and val accuracy 0.825\n",
      "/content/drive/My Drive/Colab Notebooks/DL/deep-learning-with-pytorch/data/quora_models/model_LSTM_acc_83.pth\n",
      "train loss 0.383 val loss 0.442 and val accuracy 0.829\n",
      "/content/drive/My Drive/Colab Notebooks/DL/deep-learning-with-pytorch/data/quora_models/model_LSTM_acc_83.pth\n",
      "train loss 0.378 val loss 0.442 and val accuracy 0.831\n",
      "/content/drive/My Drive/Colab Notebooks/DL/deep-learning-with-pytorch/data/quora_models/model_LSTM_acc_83.pth\n",
      "train loss 0.375 val loss 0.445 and val accuracy 0.829\n",
      "/content/drive/My Drive/Colab Notebooks/DL/deep-learning-with-pytorch/data/quora_models/model_LSTM_acc_83.pth\n",
      "train loss 0.370 val loss 0.444 and val accuracy 0.830\n",
      "/content/drive/My Drive/Colab Notebooks/DL/deep-learning-with-pytorch/data/quora_models/model_LSTM_acc_83.pth\n"
     ]
    }
   ],
   "source": [
    "train_epocs(model, optimizer, train_dl, valid_dl, 'LSTM', epochs=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tdwmnlO6m-d0"
   },
   "source": [
    "## Testing model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mcvB3f6w-IV4"
   },
   "outputs": [],
   "source": [
    "# Predict test data using best model\n",
    "def test_val(model, test_dl):\n",
    "  model.eval()\n",
    "  y_t = []\n",
    "  for x1, x2, y in test_dl:\n",
    "    x1 = x1.long().cuda()\n",
    "    x2 = x2.long().cuda()\n",
    "    y_pred = model(x1, x2)\n",
    "    y_t.append(y_pred.tolist())\n",
    "  flat_list = [item for sublist in y_t for item in sublist]\n",
    "  return flat_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cOx9TTWeJ7Jb"
   },
   "outputs": [],
   "source": [
    "best_model = LSTMV0Model(len(embeddings), 300, 100, pretrained_weights=embeddings).cuda()\n",
    "load_model(best_model, '/content/drive/My Drive/Colab Notebooks/DL/deep-learning-with-pytorch/data/quora_models/model_LSTM_acc_83.pth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VpWTk5s276Nh"
   },
   "outputs": [],
   "source": [
    "# Predict test data and write to file\n",
    "def predTest(best_model, n):\n",
    "  for i in range(n):\n",
    "    filename = \"output\"+str(i)+\".pkl\"\n",
    "    test_df = pd.read_pickle(PATH/filename)\n",
    "    X_test = np.array(test_df[['question1', 'question2']])\n",
    "    y_test = np.zeros(X_test.shape[0])\n",
    "    test_ds = QuoraDataset(X_test, y_test)\n",
    "    test_dl = DataLoader(test_ds, batch_size=100)\n",
    "    res = test_val(best_model, test_dl)\n",
    "    res = np.asarray(res)\n",
    "    res = pd.DataFrame(res)\n",
    "    pred_filename = \"submission_\"+str(i)+\".csv\"\n",
    "    res.to_csv(PATH/pred_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8v9jmHeW8tIV"
   },
   "outputs": [],
   "source": [
    "predTest(best_model, 357)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Dsh-ZKKFK5YJ"
   },
   "outputs": [],
   "source": [
    "for i in range(357):\n",
    "  pred_filename = \"submission_\"+str(i)+\".csv\"\n",
    "  sub_df = pd.read_csv(PATH/pred_filename)\n",
    "  sub_df.to_csv(PATH/'pred10.csv', mode='a',header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "98JZfnQxMQbR"
   },
   "outputs": [],
   "source": [
    "sub_df = pd.read_csv(PATH/'pred10.csv', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "PDCUVVUK1fOj",
    "outputId": "04856114-1db9-445d-855f-3047daa68c10"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3563475, 3)"
      ]
     },
     "execution_count": 441,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "G7W1M80AMWpX",
    "outputId": "3a96b1c7-780b-434f-ca95-7f14d4817f7d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3563475, 3)"
      ]
     },
     "execution_count": 236,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "eCcM30HZuIe0",
    "outputId": "aa852206-3d41-469c-8a98-6e52d5af7141"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 442,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub_df[0].duplicated().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2H2oVoxWudTb"
   },
   "outputs": [],
   "source": [
    "del sub_df[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zNGd8CVVuqJZ"
   },
   "outputs": [],
   "source": [
    "sub_df[1] = test_df[\"test_id\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bwANxAx3uycd"
   },
   "outputs": [],
   "source": [
    "sub_df.rename(columns = {1:'test_id', 2:'is_duplicate' }, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7NzXSTBevIGV"
   },
   "outputs": [],
   "source": [
    "sub_df_C = sub_df.head(2345796)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "YDYKvZp2vaq6",
    "outputId": "4b473ade-4e12-41c3-bb88-c23dcb9a9dae"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2345796, 2)"
      ]
     },
     "execution_count": 447,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub_df_C.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YC6rX1jwhaEc"
   },
   "outputs": [],
   "source": [
    "sub_df_C.to_csv(PATH/\"submission.csv\")\n",
    "sub_df_C = pd.read_csv(PATH/\"submission.csv\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5zvJdfva5MYn"
   },
   "outputs": [],
   "source": [
    "#sub_df_C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dPBRQkEhhS_L"
   },
   "outputs": [],
   "source": [
    "sub_df_C['test_id'] = sub_df_C['Unnamed: 0']\n",
    "del sub_df_C['Unnamed: 0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "iIdCzSxGhBAx",
    "outputId": "2c8ddce0-773b-4186-bc28-bd798129d094"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 451,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub_df_C['test_id'].duplicated().any()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "s25Jhi835RVI",
    "outputId": "571ce487-2e3d-425e-a720-de0d556508c7"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_id</th>\n",
       "      <th>is_duplicate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.013765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.116521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.556008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.038203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.587574</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   test_id  is_duplicate\n",
       "0        0      0.013765\n",
       "1        1      0.116521\n",
       "2        2      0.556008\n",
       "3        3      0.038203\n",
       "4        4      0.587574"
      ]
     },
     "execution_count": 455,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub_df_C.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KuI3fEo7vRGq"
   },
   "outputs": [],
   "source": [
    "sub_df_C.to_csv(PATH/\"submission.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HTOO157TmsqX"
   },
   "source": [
    "## GRU Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CD0KL4dqVUUE"
   },
   "outputs": [],
   "source": [
    "class GRUV0Model(torch.nn.Module) :\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, glove_weights=None) :\n",
    "        super(GRUV0Model,self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.embeddings = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)\n",
    "        if glove_weights is not None:\n",
    "            self.embeddings.weight.data.copy_(torch.from_numpy(glove_weights))\n",
    "            self.embeddings.weight.requires_grad = False ## freeze embeddings\n",
    "\n",
    "        self.q1_gru = nn.GRU(embedding_dim, hidden_dim, batch_first=True)\n",
    "        self.q2_gru = nn.GRU(embedding_dim, hidden_dim, batch_first=True)\n",
    "        \n",
    "    def forward(self, x1, x2):\n",
    "        x1 = self.embeddings(x1)\n",
    "        x2 = self.embeddings(x2)\n",
    "        out_pack, ht1 = self.q1_gru(x1)\n",
    "        out_pack, ht2 = self.q2_gru(x2)\n",
    "        \n",
    "        q1 = ht1[-1]\n",
    "        q2 = ht2[-1]\n",
    "        \n",
    "        dist = torch.norm(q1-q2, dim=1)\n",
    "        dist = torch.exp(-dist)\n",
    "        return dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sMmxDIC0u22L"
   },
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "train_dl = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
    "valid_dl = DataLoader(valid_ds, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DFYqLYiPVqH3"
   },
   "outputs": [],
   "source": [
    "model = GRUV0Model(len(embeddings), 300, 100, glove_weights=embeddings).cuda()\n",
    "\n",
    "parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
    "optimizer = torch.optim.Adam(parameters, lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 527
    },
    "colab_type": "code",
    "id": "r6oxxPQIVr8A",
    "outputId": "647af9e8-e442-461d-c296-6a46b3126ccf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss 0.544 val loss 0.505 and val accuracy 0.759\n",
      "/content/drive/My Drive/Colab Notebooks/DL/deep-learning-with-pytorch/data/quora_models/model_GRU_acc_76.pth\n",
      "train loss 0.490 val loss 0.484 and val accuracy 0.772\n",
      "/content/drive/My Drive/Colab Notebooks/DL/deep-learning-with-pytorch/data/quora_models/model_GRU_acc_77.pth\n",
      "train loss 0.468 val loss 0.473 and val accuracy 0.778\n",
      "/content/drive/My Drive/Colab Notebooks/DL/deep-learning-with-pytorch/data/quora_models/model_GRU_acc_78.pth\n",
      "train loss 0.454 val loss 0.464 and val accuracy 0.784\n",
      "/content/drive/My Drive/Colab Notebooks/DL/deep-learning-with-pytorch/data/quora_models/model_GRU_acc_78.pth\n",
      "train loss 0.444 val loss 0.456 and val accuracy 0.790\n",
      "/content/drive/My Drive/Colab Notebooks/DL/deep-learning-with-pytorch/data/quora_models/model_GRU_acc_79.pth\n",
      "train loss 0.436 val loss 0.457 and val accuracy 0.788\n",
      "/content/drive/My Drive/Colab Notebooks/DL/deep-learning-with-pytorch/data/quora_models/model_GRU_acc_79.pth\n",
      "train loss 0.429 val loss 0.449 and val accuracy 0.794\n",
      "/content/drive/My Drive/Colab Notebooks/DL/deep-learning-with-pytorch/data/quora_models/model_GRU_acc_79.pth\n",
      "train loss 0.423 val loss 0.447 and val accuracy 0.794\n",
      "/content/drive/My Drive/Colab Notebooks/DL/deep-learning-with-pytorch/data/quora_models/model_GRU_acc_79.pth\n",
      "train loss 0.418 val loss 0.444 and val accuracy 0.796\n",
      "/content/drive/My Drive/Colab Notebooks/DL/deep-learning-with-pytorch/data/quora_models/model_GRU_acc_80.pth\n",
      "train loss 0.414 val loss 0.441 and val accuracy 0.797\n",
      "/content/drive/My Drive/Colab Notebooks/DL/deep-learning-with-pytorch/data/quora_models/model_GRU_acc_80.pth\n",
      "train loss 0.410 val loss 0.442 and val accuracy 0.798\n",
      "/content/drive/My Drive/Colab Notebooks/DL/deep-learning-with-pytorch/data/quora_models/model_GRU_acc_80.pth\n",
      "train loss 0.406 val loss 0.443 and val accuracy 0.797\n",
      "/content/drive/My Drive/Colab Notebooks/DL/deep-learning-with-pytorch/data/quora_models/model_GRU_acc_80.pth\n",
      "train loss 0.403 val loss 0.440 and val accuracy 0.799\n",
      "/content/drive/My Drive/Colab Notebooks/DL/deep-learning-with-pytorch/data/quora_models/model_GRU_acc_80.pth\n",
      "train loss 0.400 val loss 0.439 and val accuracy 0.800\n",
      "/content/drive/My Drive/Colab Notebooks/DL/deep-learning-with-pytorch/data/quora_models/model_GRU_acc_80.pth\n",
      "train loss 0.397 val loss 0.439 and val accuracy 0.799\n",
      "/content/drive/My Drive/Colab Notebooks/DL/deep-learning-with-pytorch/data/quora_models/model_GRU_acc_80.pth\n"
     ]
    }
   ],
   "source": [
    "train_epocs(model, optimizer, train_dl, valid_dl, 'GRU', epochs=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ukXtnpjQnKFl"
   },
   "source": [
    "## Conclusion\n",
    "\n",
    "Best validation accuracy is 0.83 using LSTM baseline model compared to GRU baseline which is 0.80"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "hw2_LSTM.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
